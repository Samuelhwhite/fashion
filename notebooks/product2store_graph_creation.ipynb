{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import fashion.preprocessing as prep\n",
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# show all results of the notebook not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This first set code generates a graph. hyperparameters that need to be in main() are in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = prep.load_shops('../data/20200120_filiali.csv', extra_info=False)\n",
    "sales = prep.load_sales('../data/20200120_sales17.csv', shops)\n",
    "weeks = 2 #this is the weeks of sales data used in the model \n",
    "edgelist_name = 'list_of_edges.csv' #this is what the graph edgelist is saved as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding product and week columns to data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('adding product and week columns to data')\n",
    "\n",
    "sales['Product'] = sales.EAN.astype(str).str[:-3]\n",
    "sales['Week'] = pd.DatetimeIndex(sales.Date.astype(str)).week \n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating product-2-store edgelist\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('generating product-2-store edgelist')\n",
    "\n",
    "Sales_per_store_sums = sales.groupby(['Product', 'StoreKey','Week'])['Volume'].sum() \n",
    "\n",
    "first_n_weeks = Sales_per_store_sums.groupby(['Product', 'StoreKey']).head(weeks)\n",
    "total_sales = first_two_weeks.groupby(['Product', 'StoreKey']).sum()\n",
    "\n",
    "max_val = total_sales.max()\n",
    "\n",
    "Product2store_graph = total_sales.reset_index()\n",
    "Product2store_graph.Volume = Product2store_graph.Volume/max_val\n",
    "\n",
    "print('done')\n",
    "\n",
    "#Sales_per_store_means = Sales_per_store_sums.groupby(['Product', 'StoreKey']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving product-2-store edgelist\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('saving product-2-store edgelist')\n",
    "#Product2store_graph.to_csv(r'Product2store_edgelist.csv', header=False, index=False) #make it a parameter!!!\n",
    "\n",
    "Product2store_graph.to_csv(r'{}'.format(edgelist_name), header=False, index=False) #make it a parameter!!!\n",
    "\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This second set of functions turns the edgelist into embeddings. This should be a separate python file! hyperparameters that need to be in main() are in the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist_name = 'list_of_edges.csv' #this is what the graph edgelist is saved as\n",
    "walk_length = 30 #sets length of the random walks\n",
    "vector_length = 10 #sets length of output vectors\n",
    "no_epochs = 20 #sets number of epoch in skip-gram training\n",
    "model_name = 'DeepWalk_embeddings.model'#what you save the model name to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading graph from edgelist\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a graph\n",
    "print('loading graph from edgelist')\n",
    "\n",
    "fh=open(edgelist_name, 'r')\n",
    "graph = nx.read_weighted_edgelist(fh,delimiter=',',nodetype = str)\n",
    "\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating adjacency matrix\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create an adjacency matrix\n",
    "\n",
    "print('creating adjacency matrix')\n",
    "\n",
    "A = nx.adjacency_matrix(graph)\n",
    "A_array = A.toarray()\n",
    "\n",
    "A_cumsum = np.cumsum(A_array,axis=1)\n",
    "matrix_lengths = A.shape[0]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dictionaries for row probabilities and matrix identities\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('creating dictionaries for row probabilities and matrix identities')\n",
    "\n",
    "row_total_probabilities = [A[x].sum() for x in range(0,matrix_lengths)]\n",
    "items = list(range(matrix_lengths))\n",
    "\n",
    "probability_dictionary = {}\n",
    "for item, probability in zip(items, row_total_probabilities):\n",
    "    probability_dictionary[item] = probability\n",
    "    \n",
    "prod_store_dict = {}\n",
    "for item2, node in zip(items, graph.nodes()):\n",
    "    prod_store_dict[item2] = node\n",
    "    \n",
    "\n",
    "def transition(x):\n",
    "    if probability_dictionary[x] == 0:\n",
    "        return x\n",
    "    else:\n",
    "        y = np.random.uniform(high=probability_dictionary[x])\n",
    "        z = np.argwhere(A_cumsum[x]>y)[0][0]\n",
    "        return z\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating random walks - may take a few minutes if long walks are chosen\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#size is how many walks, the range is how many steps in each walk\n",
    "\n",
    "print('generating random walks - may take a few minutes if long walks are chosen')\n",
    "\n",
    "random_walks = list(range(matrix_lengths)) + list(range(matrix_lengths))\n",
    "\n",
    "#change it so you do a walk for every node \n",
    "# rather than randomly choosing nodes to walk with \n",
    "\n",
    "row = random_walks\n",
    "\n",
    "for null in range(0,walk_length):\n",
    "    next_node =  np.asarray([transition(oof) for oof in row])\n",
    "    random_walks = np.vstack((random_walks, next_node))\n",
    "    row = random_walks[:][-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "walk_list = random_walks.T.tolist()\n",
    "\n",
    "#str_walk_list = [list(map(str, walk)) for walk in walk_list]    \n",
    " \n",
    "str_walk_list = [[prod_store_dict[thing] for thing in walk] for walk in walk_list]   \n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running word2vec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11279972, 11431560)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#running Word2Vec\n",
    "\n",
    "print('running word2vec')\n",
    "\n",
    "model = Word2Vec(size = vector_length, window = 4, sg = 1, hs = 0,\n",
    "                 negative = 10, # for negative sampling\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "\n",
    "model.build_vocab(str_walk_list, progress_per=2)\n",
    "\n",
    "\n",
    "model.train(str_walk_list, total_examples = model.corpus_count, epochs=no_epochs, report_delay=1)\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('saving model')\n",
    "model.save('{}'.format(model_name))\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Word2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2089434001', 0.9555003046989441),\n",
       " ('2087127002', 0.9542059898376465),\n",
       " ('2088273004', 0.9537729620933533),\n",
       " ('2087847002', 0.949905514717102),\n",
       " ('2088979001', 0.9473111033439636),\n",
       " ('2094439002', 0.9453172087669373),\n",
       " ('2090127001', 0.9433228969573975),\n",
       " ('2094639001', 0.9402214288711548),\n",
       " ('2089429002', 0.9385861754417419),\n",
       " ('2095030001', 0.9385299682617188)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.most_similar('2025443001')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
